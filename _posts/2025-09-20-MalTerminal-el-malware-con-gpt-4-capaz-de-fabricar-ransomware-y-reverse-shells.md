---
title: "MalTerminal: el malware con GPT-4 capaz de fabricar ransomware y reverse shells"
date: 2025-09-20 09:00:00 
categories: [CIBERATAQUES]
tags: [ciberataques, hacking, IA, phishing, malware]
description: Creación de malware y ransomware Investigadores de ciberseguridad han descubierto lo que, según afirman, es el ejemplo más antiguo conocido hasta la fecha de malware que integra capacidades de Grandes Modelos de Lenguaje (LLM). 
image: /assets/169/preview1.png
---

El malware ha sido bautizado como MalTerminal por el equipo de investigación de SentinelOne SentinelLABS. Los hallazgos se presentaron en la conferencia de seguridad LABScon 2025.

En un informe que examina el uso malicioso de los LLM, la empresa de ciberseguridad afirmó que los actores de amenazas utilizan cada vez más modelos de IA para soporte operativo, así como para integrarlos en sus herramientas.

Esta categoría emergente se denomina malware con LLM integrado, ejemplificada por la aparición de  los siguientes malware:

- LAMEHUG (aka PROMPTSTEAL) utiliza LLM para generar comandos basados ​​en su representación textual. La actividad se ha atribuido con un nivel de confianza medio al grupo APT28 (Fancy Bear, Forest Blizzard, Sednit, Sofacy y UAC-0001) patrocinado por el estado ruso.
- PromptLock, escrita en Golang, la variante identificada por ESET utiliza el modelo GPT-OSS:20b de OpenAI localmente a través de la API de Ollama para generar scripts LUA maliciosos en tiempo real. OpenAI lanzó este modelo de lenguaje a principios de este mes. Los autores del estudio académico, Ransomware 3.0: Autocomposición y Orquestado por LLM, se han puesto en contacto con ESET Research indicando que el prototipo de investigación se asemeja mucho a las muestras de PromptLock descubiertas en VirusTotal. Esto respalda la idea de que PromptLock era una prueba de concepto, y no un malware completamente operativo.
- MalTerminal, que utiliza OpenAI GPT-4 para generar dinámicamente código de ransomware o una shell inversa. No hay evidencia que sugiera que se haya implementado en la práctica, lo que plantea la posibilidad de que también pueda ser un malware de prueba de concepto o una herramienta de RedTeam.

*"MalTerminal contenía un endpoint de la API de chat de OpenAI que quedó obsoleto a principios de noviembre de 2023, lo que sugiere que la muestra se escribió antes de esa fecha y probablemente convierte a MalTerminal en el primer hallazgo de malware con LLM habilitado"*, afirmaron los investigadores Alex Delamotte, Vitaly Kamluk y Gabriel Bernadett-Shapiro.

Junto con el binario de Windows se encuentran varios scripts de Python, algunos de los cuales son funcionalmente idénticos al ejecutable, ya que piden al usuario elegir entre "ransomware" y "shell inversa". También existe una herramienta de defensa llamada FalconShield que busca patrones en un archivo Python de destino y solicita al modelo GPT que determine si es malicioso y genere un informe de "análisis de malware".

![Imagen 01](/assets/169/169-01.jpg)

*"La incorporación de LLM al malware marca un cambio cualitativo en la estrategia de los adversarios"*, afirmó SentinelOne. Con la capacidad de generar lógica y comandos maliciosos en tiempo de ejecución, el malware habilitado con LLM presenta nuevos desafíos para los defensores.

### Evasión de las capas de seguridad del correo electrónico mediante LLM

La adopción empresarial de herramientas de IA generativa no solo está transformando las industrias, sino que también proporciona un terreno fértil para los ciberdelincuentes, que las utilizan para llevar a cabo estafas de phishing, desarrollar malware y respaldar diversos aspectos del ciclo de vida del ataque.

Los hallazgos surgen de un informe de StrongestLayer, que descubrió que los actores de amenazas incorporan mensajes ocultos en correos electrónicos de phishing para engañar a los escáneres de seguridad con IA, de modo que ignoren el mensaje y permitan que llegue a las bandejas de entrada de los usuarios. Algo similar a lo que le ocurría a GMail con los resumenes de mensajes.

Las campañas de phishing se han basado durante mucho tiempo en la ingeniería social para engañar a usuarios desprevenidos, pero el uso de herramientas de IA ha elevado estos ataques a un nuevo nivel de sofisticación, aumentando la probabilidad de interacción y facilitando que los actores de amenazas se adapten a las cambiantes defensas del correo electrónico.

El correo electrónico en sí es bastante sencillo: se hace pasar por una discrepancia de facturación e insta a los destinatarios a abrir un archivo adjunto en HTML. Pero lo insidioso es la inyección de un mensaje en el código HTML del mensaje, que se oculta al configurar el atributo de estilo como *"display:none; color:white; font-size:1px;"*.

![Imagen 02](/assets/169/169-02.png)

Como resultado, cuando el destinatario abre el archivo adjunto HTML, se desencadena una cadena de ataque que explota una vulnerabilidad de seguridad conocida como Follina (CVE-2022-30190, CVSS: 7.8) para descargar y ejecutar una carga útil de aplicación HTML (HTA). Esta, a su vez, descarga un script de PowerShell responsable de obtener malware adicional, deshabilitar el antivirus Microsoft Defender y establecer la persistencia en el host.

![Imagen 03](/assets/169/169-03.png)

StrongestLayer afirmó que tanto los archivos HTML como los HTA utilizan una técnica llamada envenenamiento LLM para eludir las herramientas de análisis de IA con comentarios de código fuente especialmente diseñados.

Según un nuevo informe de Trend Micro, desde enero de 2025 se ha intensificado la cantidad de campañas de ingeniería social que utilizan creadores de sitios web con IA, como Lovable, Netlify y Vercel, para alojar páginas CAPTCHA falsas que conducen a sitios web de phishing, desde donde se pueden robar las credenciales de los usuarios y otra información confidencial.

*"Primero se muestra un CAPTCHA a las víctimas, lo que reduce las sospechas, mientras que los escáneres automáticos solo detectan la página de desafío, pasando por alto la redirección oculta que recopila credenciales"*, afirmaron los investigadores Ryan Flores y Bakuei Matsukawa. *"Los atacantes aprovechan la facilidad de implementación, el alojamiento gratuito y la credibilidad de la marca de estas plataformas"*.

